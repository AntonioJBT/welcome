#####################
22 Dec 2016
Antonio
#####################

#####################
General approach:
- The core idea is about reproducibility, integrating best practice, creating good habits and learning together.
- Reproducibility is the key principle. This (simply but not easily) requires discipline and a few tools that 
can be used and/or understood by as many people as possible.

- Our research needs to be:
	- Reproducible (same question, same data, same code, same results)
	- Replicable (by other labs using other experiments, data, analysis, technology, etc.)
	- And ideally open source, open access and open data with code that is re-usable (by us and others)

- The above requires:
	- Clear questions and hypotheses
	- Accessible, read-only data (data collection and experiments largely already follow these guidelines but the same applies)
	- Transparent, easy to read, well documented code
	- Transparent, easy to read, well documented workflows (e.g. data processing steps and analysis)
	- Software version control
	- Computer environment logging (e.g. what tools, what versions, what OS)
	- Parameter logging

- There are many guidelines and thoughts (see below for a few suggestions).

- Data analysis (of any size) should aim to have:
	- Clear, documented code
	- Ideally automation and re-usability
	- Unit testing at its basic: do my new code changes change my expected results?
#####################


#####################
Suggested tools and approach to implement in computational and statistical analysis

- There are many tools out there that aim to put the above into practice (see list of pipeline review references for example).

- We don't need to re-invent the wheel, simply to make best use of our collective skills and existing tools/approaches.
- Languages and tools are secondary (only to an extent).

- However...:

- The general (suggested) approach is based on basic python organisation:
	+ Scripts - Write stand-alon scripts which are callable from the CLI and can take arbitrary parameters
	+ Modules - Include functions and code, which could be used by more than one script/pipeline, bundled by overall aim
	+ Pipeline - a (ruffus) python script which chains multiple tasks and jobs and can be submitted to the cluster (managed by drmaa).
	+ And ideally:
		+ Unit tests - aim to test each script, parameter, function, with small, example data. Aimed for stability only (ie do new code changes mess up the expected results?). Use via Travis CI or Jenkins CI, integrated to GitHub (tests are automatically triggered after each commit, need configuration (eg yaml), data and expected result).
		+ Report - aim to write a basic automated report that picks up some basic stats and plots for the pipeline (sphinx, markdown, or similar for example).

- The general approach I'm suggesting is the one followed by CGAT, which in turn adopts many current computational best practice standards). See:
https://github.com/CGATOxford
https://github.com/CGATOxford/cgat
https://github.com/CGATOxford/CGATPipelines

- A lot of this work is in beta (as are most pipeline approaches, of which there are many).

#####################


#####################
- Some tutorials:

Github:
15 minute intro to GitHub:
https://try.github.io/levels/1/challenges/1

Other training resources:
http://swcarpentry.github.io/git-novice/
https://github.github.io/on-demand/
https://services.github.com/training/

Unix and command line basics:
http://www.ee.surrey.ac.uk/Teaching/Unix/index.html
http://swcarpentry.github.io/shell-novice/
https://www.codecademy.com/learn/learn-the-command-line
#####################


#####################
- A few references on data analysis and reproducibility:

PLOS Biology: Best Practices for Scientific Computing
http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1001745

PLOS Computational Biology: A Quick Guide to Organizing Computational 
Biology Projects
http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000424

PLOS Computational Biology: Ten Simple Rules for a Computational 
Biologistâ€™s Laboratory Notebook
http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004385

Reproducible Research in Computational Science | Science
http://science.sciencemag.org/content/334/6060/1226

Enhancing reproducibility for computational methods
http://science.sciencemag.org/content/354/6317/1240.full

Liberating field science samples and data | Science
http://science.sciencemag.org/content/351/6277/1024.full

Promoting an open research culture | Science
http://science.sciencemag.org/content/348/6242/1422.full
#####################
